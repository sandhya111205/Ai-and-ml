{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandhya111205/Ai-and-ml/blob/main/LR_With_without_Built_In_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression** - is a powerful and widely used algorithm in supervised learning within machine learning. It's primarily used for classification tasks, particularly those involving binary outcomes: yes/no, true/false, or 0/1.\n",
        "\n",
        "**What it does:**\n",
        "It models the relationship between one or more independent variables (features) and a single binary dependent variable.\n",
        "It predicts the probability of an event occurring, instead of simply providing a yes/no answer.\n",
        "This probability output allows for more nuanced interpretations and decision-making.\n",
        "\n",
        "**How it works:**\n",
        "Under the hood, it utilizes a sigmoid function that transforms a linear equation into a smooth S-shaped curve.\n",
        "This curve maps any real-valued input from the feature space to a probability between 0 and 1.\n",
        "By training the model on labeled data, the coefficients of the linear equation are adjusted to best estimate the true probabilities underlying the relationship between features and the outcome.\n",
        "\n",
        "**When to use it:**\n",
        "When you have a binary classification problem.\n",
        "When you want to understand the influence of each feature on the outcome through the learned coefficients.\n",
        "When interpretability and explainability of the model are important.\n",
        "\n",
        "**Advantages:**\n",
        "Simple to implement and understand.\n",
        "Efficient and computationally inexpensive.\n",
        "Provides probabilistic outputs for informed decision-making.\n",
        "Offers interpretability through feature coefficients.\n",
        "\n",
        "**Disadvantages:**\n",
        "Limited to binary classification tasks.\n",
        "Assumes a linear relationship between features and the outcome.\n",
        "May not perform well with complex data or highly non-linear relationships.\n",
        "\n",
        "Examples of applications: **bold text**\n",
        "Predicting spam emails.\n",
        "Identifying fraudulent transactions.\n",
        "Classifying medical images as cancerous or benign.\n",
        "Assessing creditworthiness of loan applicants.\n",
        "\n",
        "**Beyond the basics:**\n",
        "Logistic regression can be extended to handle multi-class classification with modifications like one-vs-rest approach.\n",
        "Regularization techniques can be used to prevent overfitting and improve model generalization.\n",
        "Logistic regression can be combined with other algorithms in ensemble methods for better performance.\n",
        "\n",
        "Other Reference Links: https://developer.ibm.com/articles/implementing-logistic-regression-from-scratch-in-python/"
      ],
      "metadata": {
        "id": "3CfqQOBYyHrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With_Built-In Function**"
      ],
      "metadata": {
        "id": "QoMG4r1zxDqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPOJlyfdbotw",
        "outputId": "5f5c4715-cca9-4298-8521-c5834af7c592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE2IVtzRBE5f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from scipy.sparse import csr_array\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/AI and ML/sample_text - Sheet1.csv')\n",
        "data"
      ],
      "metadata": {
        "id": "6lAHauwKCAgp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "70005b23-2650-46a9-ea77-3571dedc3b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                tweet_id                                               text  \\\n",
              "0    1123757263427186690  hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...   \n",
              "1    1123733301397733380  RT @airjunebug: When you're from the Bay but y...   \n",
              "2    1123734094108659712  RT @DonaldJTrumpJr: Dear Democrats: The Americ...   \n",
              "3    1126951188170199049  RT @SheLoveTimothy: He ainâ€™t on drugs he just ...   \n",
              "4    1126863510447710208  RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...   \n",
              "..                   ...                                                ...   \n",
              "995  1126798721025544193  RT @prodnose: Good morning, everyone.\\nFollowi...   \n",
              "996  1126833089190219777  @cheezitking123 this what you get for tryna ge...   \n",
              "997  1130037092845670400                               earphones ko ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­   \n",
              "998  1127028455651123201  RT @nj_linguist: @realgonegirl @elivalley I th...   \n",
              "999  1130285076858789889  iâ€™m tired as fuck. and man, physically ainâ€™t S...   \n",
              "\n",
              "    task1  \n",
              "0     HOF  \n",
              "1     HOF  \n",
              "2     NOT  \n",
              "3     HOF  \n",
              "4     NOT  \n",
              "..    ...  \n",
              "995   NOT  \n",
              "996   NOT  \n",
              "997   NOT  \n",
              "998   NOT  \n",
              "999   HOF  \n",
              "\n",
              "[1000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fee1eac-3653-44fe-8041-5387601e220a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1123757263427186690</td>\n",
              "      <td>hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...</td>\n",
              "      <td>HOF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1123733301397733380</td>\n",
              "      <td>RT @airjunebug: When you're from the Bay but y...</td>\n",
              "      <td>HOF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1123734094108659712</td>\n",
              "      <td>RT @DonaldJTrumpJr: Dear Democrats: The Americ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1126951188170199049</td>\n",
              "      <td>RT @SheLoveTimothy: He ainâ€™t on drugs he just ...</td>\n",
              "      <td>HOF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1126863510447710208</td>\n",
              "      <td>RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1126798721025544193</td>\n",
              "      <td>RT @prodnose: Good morning, everyone.\\nFollowi...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1126833089190219777</td>\n",
              "      <td>@cheezitking123 this what you get for tryna ge...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1130037092845670400</td>\n",
              "      <td>earphones ko ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1127028455651123201</td>\n",
              "      <td>RT @nj_linguist: @realgonegirl @elivalley I th...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1130285076858789889</td>\n",
              "      <td>iâ€™m tired as fuck. and man, physically ainâ€™t S...</td>\n",
              "      <td>HOF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fee1eac-3653-44fe-8041-5387601e220a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4fee1eac-3653-44fe-8041-5387601e220a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4fee1eac-3653-44fe-8041-5387601e220a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a435351e-bdb5-4245-8646-9333ef1c6db6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a435351e-bdb5-4245-8646-9333ef1c6db6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a435351e-bdb5-4245-8646-9333ef1c6db6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_709f03da-588a-4381-9818-715303540703\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_709f03da-588a-4381-9818-715303540703 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['text']= label_encoder.fit_transform(data['text'])\n",
        "data['text'].unique()"
      ],
      "metadata": {
        "id": "3MUlZv9bL7aZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408f767c-70ac-4abc-d0df-f25204e62aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([954, 614, 443, 558, 578,  55, 826, 378, 301,  90, 366, 841, 845,\n",
              "       218, 330, 274, 313, 868, 116, 519, 743, 487,  16, 226, 865, 143,\n",
              "       591,  70, 468, 788, 495, 809, 516, 465, 513, 917, 180, 946, 888,\n",
              "       858, 693, 982, 635,  33, 694, 110,  98, 405, 850, 125, 869, 573,\n",
              "       664, 299,  65, 160, 983, 522, 786, 436, 191, 387, 866,  92, 233,\n",
              "       821, 955, 564, 951, 977, 373, 822, 402, 281, 784, 633, 385, 133,\n",
              "       565, 294, 476, 370,  34, 612, 260,  37, 937, 878, 461, 839, 426,\n",
              "       439,  96, 474, 121, 607, 997,  62, 646, 762, 734, 806, 978, 947,\n",
              "       718, 798, 339,  77, 800, 639, 340, 338, 147, 349, 374, 856,  51,\n",
              "       770, 496, 262, 427, 569, 144, 900, 106, 916, 310,  61, 126, 433,\n",
              "       748, 802,  24, 289, 508, 293,  59, 790, 747,  66, 155, 566, 532,\n",
              "        43, 577, 510, 941, 634, 253, 592, 557, 199, 985, 610, 675, 778,\n",
              "       350, 198, 602, 531,   9, 234, 749, 381, 650, 417, 148, 145, 989,\n",
              "       285,   4, 724, 936, 597, 980, 604, 547, 717, 814, 714, 799,   5,\n",
              "        99, 130, 325, 915, 971, 925, 288, 741, 923, 135, 528, 371, 206,\n",
              "       700, 574, 831,  75, 372, 846, 976, 721, 429, 803, 683, 509, 677,\n",
              "       162, 492,  28, 409,  81, 503, 742,  68,  22,  12, 587,  86, 903,\n",
              "       887, 687,  53, 944, 137, 424, 186, 292, 261, 485, 550, 205, 733,\n",
              "       283, 953, 834, 560, 857, 473, 413, 585, 874, 334, 252, 132, 816,\n",
              "       375, 321, 458, 342, 688, 410, 600, 811, 562, 876,  27, 157, 776,\n",
              "       211, 972, 399, 896, 864, 599, 187, 673, 500, 111,  88, 131, 217,\n",
              "       142, 883, 437,  35, 720, 836, 529, 223, 912, 995, 960, 193, 190,\n",
              "       670, 161, 886, 774, 346, 214, 377, 316, 247, 455, 961, 676,  84,\n",
              "       652, 819, 636, 542, 118, 862, 842, 914, 793, 590, 922,  80, 265,\n",
              "       787, 269, 698, 605, 317,  52, 462, 526, 881, 771, 308, 873, 727,\n",
              "       766, 395, 535, 848, 440, 412, 298, 128, 702, 345, 108, 818,  41,\n",
              "       986, 518, 114,  60, 428,  79, 892, 619, 538, 867, 238, 755, 686,\n",
              "       488, 227, 648, 957,  31, 773, 460, 369, 750, 572, 852, 445, 707,\n",
              "       891, 723, 984,  67, 228,  42, 709, 704,  71, 927, 302, 240, 235,\n",
              "       835, 156, 593, 355, 739, 679, 649, 343, 411, 958,  49, 579, 546,\n",
              "       179, 400, 708, 192, 396, 681, 480,  95, 609, 203, 332, 224, 249,\n",
              "       992, 107, 337, 830, 815, 483, 882, 725,  97, 195, 479, 794, 849,\n",
              "       710, 276, 603, 103, 851, 663, 885, 781, 792, 642, 752, 924, 589,\n",
              "       620, 659, 661, 392, 684, 464, 541, 306, 327, 641, 109, 119, 823,\n",
              "       264, 711, 352,  15, 257,  58, 200, 389,  39, 644, 871, 521, 797,\n",
              "        20, 561, 297, 745, 780, 697, 732, 678, 273, 777, 134, 715, 813,\n",
              "       611, 890, 801, 817, 216, 899, 563, 453, 246,  85, 812, 239, 129,\n",
              "         0, 514, 920, 335, 523, 656, 254, 893, 354, 407, 138, 832, 889,\n",
              "       490, 275, 100, 242, 398, 796, 463,  72, 291, 956, 632, 168, 854,\n",
              "       344, 165, 595, 567, 403, 863, 102, 284, 364, 303,  21, 286, 115,\n",
              "       329, 877, 722, 993, 730, 309, 406, 420, 729, 643, 884, 897, 255,\n",
              "       506, 638, 449, 394, 304, 568, 933, 357, 651, 629, 576, 736, 959,\n",
              "       556, 716, 940, 328, 489, 268, 631, 459, 975, 105, 282, 201, 336,\n",
              "       682, 469, 278, 300, 266, 671, 166, 667, 220, 653, 669, 901, 962,\n",
              "       219, 207,  74, 215,  56, 950, 685, 393, 326, 952,  63, 548, 930,\n",
              "       586, 909, 212, 391, 122,  10,  76, 537, 421, 630, 358, 384,  94,\n",
              "       551, 197, 324,  40, 973, 666, 425, 772, 703, 315,  32, 768, 533,\n",
              "       911, 767, 575, 231, 181, 232, 674, 408,  69, 202, 625, 807, 113,\n",
              "       921, 290, 123, 318, 305, 229, 791, 746, 185, 348,  93, 988, 442,\n",
              "       466, 728, 624, 804, 934, 654, 432, 169, 184, 628, 230, 991,  38,\n",
              "       477, 530, 938, 779,  78, 970,  25, 910, 689,  23, 657,  17, 840,\n",
              "       494, 907, 295, 712, 549, 164, 120, 418,   7, 367, 312,  36, 908,\n",
              "       279, 837,   1,  82, 553, 150, 173, 926, 853, 450, 101,  50,   6,\n",
              "        46, 177, 171, 404,  64, 751, 918, 608, 431, 872, 351, 139, 361,\n",
              "        73, 163, 981, 141, 438, 222, 665, 581, 860, 320, 939,  19, 979,\n",
              "       525, 475, 719, 505, 435, 127, 843, 622, 999, 524, 757, 386, 467,\n",
              "       470, 146, 894, 182, 895, 447, 311,   2, 769, 904,  18, 280, 555,\n",
              "       178, 307, 478, 613, 536, 615,  48,   8, 844, 738, 204, 507, 928,\n",
              "       422, 942, 795, 783, 775, 482, 618, 726, 879, 270, 699, 414, 267,\n",
              "       341, 136, 430, 323, 759, 484, 314, 898, 805, 744, 333, 740, 209,\n",
              "        57, 210, 189, 491, 170, 331,  44,  30, 855,  89, 376, 457, 598,\n",
              "       497, 931, 244, 974, 379, 617, 761, 827, 737, 452, 660, 753,  91,\n",
              "       662, 544, 271, 825, 668,  87, 124, 623, 356, 380, 368, 906, 626,\n",
              "       948, 658, 672, 241, 690, 401, 188, 382, 994, 365, 471, 448, 183,\n",
              "       520, 383, 277, 245, 990, 117, 208, 692, 833, 594, 705, 760, 515,\n",
              "        13, 582,   3, 498, 545, 504, 655,  47, 175, 968, 225, 104, 502,\n",
              "       360, 838, 828, 637, 158, 764, 763, 969, 446, 322, 539, 251, 859,\n",
              "       996, 194, 416, 512, 419, 847, 388, 691, 935, 154, 880,  54,  11,\n",
              "       829, 808, 263, 140, 967, 695, 176, 964, 987, 570, 258, 606, 153,\n",
              "       552, 943, 861, 913, 256, 584, 172, 949, 647, 540, 415, 517, 596,\n",
              "       472, 966, 534, 287, 588, 756, 167, 905, 363, 820, 706, 758, 493,\n",
              "       554, 559, 543, 583, 456, 499,  26, 621, 296, 362,  14, 213, 701,\n",
              "       511, 243, 785, 151, 152, 919, 571, 236, 640, 347, 259, 870,  29,\n",
              "        45, 248,  83, 731, 441, 221, 616, 929, 810, 444, 353, 932, 875,\n",
              "       824, 434, 601, 451, 397, 423, 765, 250, 680, 580, 645, 998, 112,\n",
              "       359, 965, 696, 627, 159, 319, 174, 501, 789, 481, 902, 237, 735,\n",
              "       486, 272, 196, 454, 713, 527, 390, 782, 149, 945, 754, 963])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data['task1']\n",
        "y= data['text']\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=1234)"
      ],
      "metadata": {
        "id": "rI3AMLpVENXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8AkTyU2Ig0c",
        "outputId": "6a6544c3-196b-4d40-d0d8-6a93fdc5c2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "281    HOF\n",
              "42     HOF\n",
              "255    NOT\n",
              "906    HOF\n",
              "394    NOT\n",
              "      ... \n",
              "204    HOF\n",
              "53     HOF\n",
              "294    HOF\n",
              "723    NOT\n",
              "815    NOT\n",
              "Name: task1, Length: 800, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "train_feature = vectorizer.fit_transform(x_train)\n",
        "test_feature  = vectorizer.transform(x_test)"
      ],
      "metadata": {
        "id": "y2ZimBUnGpVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_feature)"
      ],
      "metadata": {
        "id": "GOC6b6FfHLbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0969063d-fcf9-45a6-b823-c352309c76da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 0)\t1.0\n",
            "  (1, 0)\t1.0\n",
            "  (2, 1)\t1.0\n",
            "  (3, 0)\t1.0\n",
            "  (4, 1)\t1.0\n",
            "  (5, 0)\t1.0\n",
            "  (6, 1)\t1.0\n",
            "  (7, 0)\t1.0\n",
            "  (8, 0)\t1.0\n",
            "  (9, 1)\t1.0\n",
            "  (10, 1)\t1.0\n",
            "  (11, 1)\t1.0\n",
            "  (12, 0)\t1.0\n",
            "  (13, 1)\t1.0\n",
            "  (14, 0)\t1.0\n",
            "  (15, 1)\t1.0\n",
            "  (16, 1)\t1.0\n",
            "  (17, 0)\t1.0\n",
            "  (18, 1)\t1.0\n",
            "  (19, 0)\t1.0\n",
            "  (20, 1)\t1.0\n",
            "  (21, 1)\t1.0\n",
            "  (22, 1)\t1.0\n",
            "  (23, 1)\t1.0\n",
            "  (24, 1)\t1.0\n",
            "  :\t:\n",
            "  (775, 1)\t1.0\n",
            "  (776, 0)\t1.0\n",
            "  (777, 0)\t1.0\n",
            "  (778, 1)\t1.0\n",
            "  (779, 1)\t1.0\n",
            "  (780, 0)\t1.0\n",
            "  (781, 0)\t1.0\n",
            "  (782, 1)\t1.0\n",
            "  (783, 1)\t1.0\n",
            "  (784, 1)\t1.0\n",
            "  (785, 0)\t1.0\n",
            "  (786, 0)\t1.0\n",
            "  (787, 0)\t1.0\n",
            "  (788, 1)\t1.0\n",
            "  (789, 0)\t1.0\n",
            "  (790, 0)\t1.0\n",
            "  (791, 1)\t1.0\n",
            "  (792, 1)\t1.0\n",
            "  (793, 0)\t1.0\n",
            "  (794, 1)\t1.0\n",
            "  (795, 0)\t1.0\n",
            "  (796, 0)\t1.0\n",
            "  (797, 0)\t1.0\n",
            "  (798, 1)\t1.0\n",
            "  (799, 1)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms_train1= train_feature.toarray()"
      ],
      "metadata": {
        "id": "CADLjMIRvNYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_test1=test_feature.toarray()"
      ],
      "metadata": {
        "id": "Ktyvyg0PwIm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "\n",
        "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # init parameters\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # gradient descent\n",
        "        for _ in range(self.n_iters):\n",
        "            # approximate output variable (y) with linear combination of weights and x, plus bias\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            # apply sigmoid function\n",
        "            y_predicted = self._sigmoid(linear_model)\n",
        "\n",
        "            # compute gradients\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y)) #derivative w.r.t weights\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)  #derivative w.r.t bias\n",
        "            # update parameters\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self._sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "        return np.array(y_predicted_cls)\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "QHDF-pi5B0Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class LogisticRegression():\n",
        "#     def __init__(self):\n",
        "#         self.losses = []\n",
        "#         self.train_accuracies = []\n",
        "\n",
        "#     def fit(self, x, y, epochs):\n",
        "#         x = self._transform_x(x)\n",
        "#         y = self._transform_y(y)\n",
        "\n",
        "#         self.weights = np.zeros(x.shape[1])\n",
        "#         self.bias = 0\n",
        "\n",
        "#         for i in range(epochs):\n",
        "#             x_dot_weights = np.matmul(self.weights, x.transpose()) + self.bias\n",
        "#             pred = self._sigmoid(x_dot_weights)\n",
        "#             loss = self.compute_loss(y, pred)\n",
        "#             error_w, error_b = self.compute_gradients(x, y, pred)\n",
        "#             self.update_model_parameters(error_w, error_b)\n",
        "\n",
        "#             pred_to_class = [1 if p > 0.5 else 0 for p in pred]\n",
        "#             self.train_accuracies.append(accuracy_score(y, pred_to_class))\n",
        "#             self.losses.append(loss)\n",
        "\n",
        "#     def compute_loss(self, y_true, y_pred):\n",
        "#         # binary cross entropy\n",
        "#         y_zero_loss = y_true * np.log(y_pred + 1e-9)\n",
        "#         y_one_loss = (1-y_true) * np.log(1 - y_pred + 1e-9)\n",
        "#         return -np.mean(y_zero_loss + y_one_loss)\n",
        "\n",
        "#     def compute_gradients(self, x, y_true, y_pred):\n",
        "#         # derivative of binary cross entropy\n",
        "#         difference =  y_pred - y_true\n",
        "#         gradient_b = np.mean(difference)\n",
        "#         gradients_w = np.matmul(x.transpose(), difference)\n",
        "#         gradients_w = np.array([np.mean(grad) for grad in gradients_w])\n",
        "\n",
        "#         return gradients_w, gradient_b\n",
        "\n",
        "#     def update_model_parameters(self, error_w, error_b):\n",
        "#         self.weights = self.weights - 0.1 * error_w\n",
        "#         self.bias = self.bias - 0.1 * error_b\n",
        "\n",
        "#     def predict(self, x):\n",
        "#         x_dot_weights = np.matmul(x, self.weights.transpose()) + self.bias\n",
        "#         probabilities = self._sigmoid(x_dot_weights)\n",
        "#         return [1 if p > 0.5 else 0 for p in probabilities]\n",
        "\n",
        "#     def _sigmoid(self, x):\n",
        "#         return np.array([self._sigmoid_function(value) for value in x])\n",
        "\n",
        "#     def _sigmoid_function(self, x):\n",
        "#         if x >= 0:\n",
        "#             z = np.exp(-x)\n",
        "#             return 1 / (1 + z)\n",
        "#         else:\n",
        "#             z = np.exp(x)\n",
        "#             return z / (1 + z)\n",
        "\n",
        "#     def _transform_x(self, x):\n",
        "#         x = copy.deepcopy(x)\n",
        "#         return x.values\n",
        "\n",
        "#     def _transform_y(self, y):\n",
        "#         y = copy.deepcopy(y)\n",
        "#         return y.values.reshape(y.shape[0], 1)"
      ],
      "metadata": {
        "id": "zlEs3wWPL3aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itr=[]\n",
        "acc=[]"
      ],
      "metadata": {
        "id": "FtjxNR4GB2eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = LogisticRegression(learning_rate=0.0001, n_iters=383)#learning_rate=0.0001, n_iters=383"
      ],
      "metadata": {
        "id": "58rXKu7uB4Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.fit(terms_train1, y_train)"
      ],
      "metadata": {
        "id": "RvvtrWrbGOI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = regressor.predict(term_test1)\n",
        "itr.append(500)"
      ],
      "metadata": {
        "id": "bUfYEwCbGPrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LR classification accuracy:\", accuracy(y_test, predictions))\n",
        "acc.append(accuracy(y_test, predictions))"
      ],
      "metadata": {
        "id": "kLdAFrOsB5Sx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e217693-ff1d-47bd-ccd4-450914835c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR classification accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Without_Built-In Function**"
      ],
      "metadata": {
        "id": "2PfM6WOhw_gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()#tol=0.0001, max_iter=383,class_weight=None,random_state=None\n",
        "clf.fit(train_feature, y_train)"
      ],
      "metadata": {
        "id": "rZSGKL2exIu6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "8eab36ed-56a0-48a1-e218-837a8c42e102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(test_feature)"
      ],
      "metadata": {
        "id": "QgE2r3XTxhCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "id": "Hd3zEwWRxkhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e76b668-6cbb-40a4-ddc9-29258ed9c018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00%\n"
          ]
        }
      ]
    }
  ]
}